{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/ouali/PRAMA_Projet/europarl-v6.fr-en.fr_toy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Charger les données\u001b[39;00m\n\u001b[0;32m     10\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/ouali/PRAMA_Projet/europarl-v6.fr-en.fr_toy\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     12\u001b[0m     text \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Prétraitement des données\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ouali\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/ouali/PRAMA_Projet/europarl-v6.fr-en.fr_toy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Charger les données\n",
    "file_path = 'C:/Users/ouali/PRAMA_Projet/europarl-v6.fr-en.fr_toy' \n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Prétraitement des données\n",
    "text = text.lower()\n",
    "words = text.split()\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(words)\n",
    "sequences = tokenizer.texts_to_sequences(words)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Création de séquences d'entraînement\n",
    "def create_sequences(words, seq_length=5):\n",
    "    sequences = []\n",
    "    for i in range(seq_length, len(words)):\n",
    "        seq = words[i-seq_length:i+1]\n",
    "        sequences.append(seq)\n",
    "    return sequences\n",
    "\n",
    "seq_length = 5\n",
    "sequences = create_sequences(sequences, seq_length)\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "# Séparation des entrées et des sorties\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Construction du modèle de réseau de neurones\n",
    "#Nous allons construire un modèle simple de réseau de neurones récurrent (LSTM) pour prédire le prochain mot.\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Définir le modèle\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=seq_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "# Compiler le modèle\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Entraînement du modèle\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_val, y_val))\n",
    "\n",
    "# Évaluer le modèle\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilisation du modèle pour le calcul de \\( P(w) \\)\n",
    "def predict_next_word(model, tokenizer, text_seq, seq_length=5):\n",
    "    encoded = tokenizer.texts_to_sequences([text_seq])[0]\n",
    "    encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "    pred = model.predict(encoded, verbose=0)\n",
    "    return pred\n",
    "\n",
    "# Exemple d'utilisation\n",
    "text_seq = 'il est'\n",
    "pred = predict_next_word(model, tokenizer, text_seq)\n",
    "predicted_word = tokenizer.index_word[np.argmax(pred)]\n",
    "print(f'Predicted word: {predicted_word}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
