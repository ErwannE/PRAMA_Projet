{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce document vise à calculer les probabilités qu'un mot tapé soit un autre mot de notre base de données.\n",
    "On part du principe qu'on a une liste de mots connus.\n",
    "On se soucie simplement de regarder la ressemblance avec d'autres mots existants, pas de regarder les mots à proximité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionnaire = ['aime', 'aimé', 'aimer', 'aimes', 'meme', 'aimez', 'mimez', 'mime', 'même', 'mimer', 'mimes', 'mimé']\n",
    "mot_tapé = \"Amies\"\n",
    "# exemple jouet, on déploiera ça de manière plus générale une fois qu'on aura la data de Quentin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode qu'on va utiliser consiste à regarder le mot tapé de gauche à droite, et de calculer le nombre de lettres différentes pour chaque mot de notre dictionnaire. Puis on attribuera a chaque erreur un score selon son importance (une faute d'accent est moins grave qu'une faute de lettre). Plus le score est élevé, plus le mot sera éloigné du mot auquel on le compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les probabilités calculées le seront a partir d'un score. Il faut considérer l'ensemble des erreurs possibles. On prend :\n",
    "- La taille du mot qui diffère (infini si trop éloigné, +3 si éloigné de deux caractères, +2 si un caractère)\n",
    "- Le nombre de lettres différentes (score plus ou moins important si les lettres sont proches de la lettre visée ou pas);\n",
    "- Eventuelles inversions de lettres (on ne considère que les lettres successives 2 par deux : aime et amie, mais pas oise et soie)\n",
    "- Fautes d'accent (+1 par faute d'accent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par mettre le mot en minuscule avant tout traitement. On lui rendra sa majuscule à la fin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amies\n"
     ]
    }
   ],
   "source": [
    "mot_tapé = mot_tapé.lower()\n",
    "print(mot_tapé)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taille du mot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On suppose que deux mots peuvent potentiellement être proches seulement s'ils ont une taille assez similaire (+2 ou -1 caractères)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_len_words_near(mot_tapé, mot_dico):\n",
    "    assert isinstance(mot_tapé, str)\n",
    "    assert isinstance(mot_dico, str)\n",
    "    n1 = len(mot_tapé)\n",
    "    n2 = len(mot_dico)\n",
    "    return ((n2-2 <= n1) & (n1 <= n2+1))\n",
    "\n",
    "is_len_words_near('aime', 'aimera')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentation du calcul du score :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1.0\n",
      "2\n",
      "inf\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def score_len(mot_tapé, mot_dico, pénalité_max=2):\n",
    "    assert isinstance(mot_tapé, str)\n",
    "    assert isinstance(mot_dico, str)\n",
    "    n1 = len(mot_tapé)\n",
    "    n2 = len(mot_dico)\n",
    "    score = 0\n",
    "    if not is_len_words_near(mot_tapé, mot_dico):\n",
    "        score = np.inf\n",
    "    elif ((n1 == n2-1) | (n1 == n2+1)):\n",
    "        score += pénalité_max/2\n",
    "    elif (n1 == n2-2):\n",
    "        score += pénalité_max\n",
    "    return score\n",
    "\n",
    "print(score_len('aime', 'mile'))\n",
    "print(score_len('aime', 'mille'))\n",
    "print(score_len( 'aime', 'aimera'))\n",
    "print(score_len('aime', 'ai'))\n",
    "print(score_len('aime', 'aie'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Première lettre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On suppose aussi que la première lettre du mot est toujours la bonne (c'est ce que font les correcteurs). Donc les mots qui ne commencent pas par la même lettre ont une probabilité nulle aussi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_first_letter_the_same(mot_tapé, mot_dico):\n",
    "    assert isinstance(mot_tapé, str)\n",
    "    assert isinstance(mot_dico, str)\n",
    "    return (mot_tapé[0] == mot_dico[0])\n",
    "\n",
    "is_first_letter_the_same('aime', 'mimer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentation du score :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_prem_lettre(mot_tapé, mot_dico):\n",
    "    assert isinstance(mot_tapé, str)\n",
    "    assert isinstance(mot_dico, str)\n",
    "    if not is_first_letter_the_same(mot_tapé, mot_dico):\n",
    "        score = np.inf\n",
    "        return score\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lettres différentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul du score pour des lettres différentes : on ajoute 2 au score si la lettre est différente et loin, 1 si elle est différente et proche, 1 si c'est une faute d'accent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_proches_clavier = {\"a\":[\"&\",\"é\",\"z\",\"s\",\"q\"],\"z\":[\"&\",\"é\",\"a\",\"s\",\"q\",\"d\",\"e\",\"\\\"\"],\"e\":[\"\\'\",\"\\\"\",\"z\",\"s\",\"f\",\"d\",\"r\"],\n",
    " \"t\":[\"-\",\"y\",\"g\",\"f\",\"h\",\"r\",\"(\"],\"y\":[\"-\",\"t\",\"g\",\"j\",\"h\",\"u\",\"è\"],\"u\":[\"_\",\"y\",\"k\",\"j\",\"h\",\"i\",\"è\"],\n",
    " \"i\":[\"_\",\"u\",\"k\",\"j\",\"l\",\"o\",\"ç\"],\"o\":[\"à\",\"i\",\"k\",\"m\",\"l\",\"p\",\"ç\"],\"p\":[\"o\",\"l\",\"m\",\"ù\",\")\",\"à\"],\n",
    " \"q\":[\"a\",\"z\",\"s\",\"w\",\"x\",\"<\"],\"s\":[\"a\",\"z\",\"k\",\"q\",\"d\",\"w\",\"x\"],\"d\":[\"s\",\"z\",\"e\",\"r\",\"f\",\"x\",\"c\"],\n",
    " \"f\":[\"e\",\"r\",\"t\",\"d\",\"g\",\"c\",\"v\"],\"g\":[\"r\",\"t\",\"y\",\"h\",\"f\",\"v\",\"b\"],\"h\":[\"t\",\"y\",\"u\",\"g\",\"j\",\"b\",\"n\"],\n",
    " \"j\":[\"u\",\"i\",\"y\",\"h\",\"k\",\"n\",\",\"],\"k\":[\"u\",\"i\",\"o\",\"j\",\"l\",\",\",\";\"],\"l\":[\"i\",\"o\",\"p\",\"k\",\"m\",\";\",\":\"],\n",
    " \"m\":[\"o\",\"p\",\"ù\",\"l\",\":\",\"!\"],\"w\":[\"<\",\"q\",\"s\",\"d\",\"x\"],\"x\":[\"q\",\"s\",\"d\",\"c\",\"w\"],\"c\":[\"s\",\"d\",\"f\",\"x\",\"v\"],\n",
    " \"v\":[\"f\",\"g\",\"c\",\"b\"],\"b\":[\"v\",\"g\",\"h\",\"n\"],\"i\":[\"b\",\"h\",\"j\",\",\"],\"r\":[\"\\'\",\"t\",\"g\",\"f\",\"d\",\"e\",\"(\"],\n",
    " \"n\":[\"b\",\"h\",\"j\"]}\n",
    "\n",
    "#création d'un mapping pour vérifier si il y a faute d'accent\n",
    "mapping_accent_to_lettre = {\"é\":\"e\", \"è\":\"e\", \"ç\":\"c\", \"à\":\"a\", \"ù\":\"u\", 'â':'a', 'ê':'e', 'î':'i', 'ô':'o', 'û':'u'}\n",
    "list_accents = ['é', \"è\",\"ç\",\"à\",\"ù\",'â','ê','î','ô', 'û']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "0\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "def score_letter_diff(lettre_tapée, lettre_dico, pénalité_max = 2):\n",
    "    '''Retourne un score de différence entre deux lettres.'''\n",
    "    assert isinstance(lettre_tapée, str)\n",
    "    assert len(lettre_tapée) == 1\n",
    "    assert isinstance(lettre_dico, str)\n",
    "    assert len(lettre_dico) == 1\n",
    "    score = 0\n",
    "    # Part 1 : lettres identiques\n",
    "    if lettre_tapée == lettre_dico:\n",
    "        return score\n",
    "    # Part 2 : fautes d'accents\n",
    "        # Cas 1 : les 2 lettres ont un accent\n",
    "    elif (lettre_tapée in (list_accents)) & (lettre_dico in (list_accents)):\n",
    "        if mapping_accent_to_lettre[lettre_tapée] == mapping_accent_to_lettre[lettre_dico]:\n",
    "            score += pénalité_max/2\n",
    "        else:\n",
    "            score += pénalité_max\n",
    "        # Cas 2:  1 des 2 lettres a un accent\n",
    "    elif (lettre_tapée in (list_accents)) & (not (lettre_dico in (list_accents))):\n",
    "        if mapping_accent_to_lettre[lettre_tapée] == lettre_dico:\n",
    "            score += pénalité_max/2\n",
    "        else:\n",
    "            score += pénalité_max\n",
    "    elif (lettre_dico in (list_accents)) & (not (lettre_tapée in (list_accents))):\n",
    "        if mapping_accent_to_lettre[lettre_dico] == lettre_tapée:\n",
    "            score += pénalité_max/2\n",
    "        else:\n",
    "            score += pénalité_max\n",
    "    \n",
    "    # Part 3 : lettres proches\n",
    "    elif lettre_dico in (dict_proches_clavier[lettre_tapée]):\n",
    "        score += pénalité_max/2\n",
    "    # Part 4 : rien de tout cela, ie lettres non proches sans faute d'accent\n",
    "    else:\n",
    "        score += pénalité_max\n",
    "    return score\n",
    "        \n",
    "    \n",
    "print(score_letter_diff(\"c\", \"ç\"))\n",
    "print(score_letter_diff(\"c\", \"v\"))\n",
    "print(score_letter_diff(\"c\", \"c\"))\n",
    "print(score_letter_diff(\"c\", \"o\"))\n",
    "print(score_letter_diff(\"m\", \"a\"))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reste à itérer sur tout le mot. On normalise pour avoir un score max d'erreurs de mot qui vaut 3 (même chose que si on a 2 lettres de différence entre les deux mots), mais il faudra le faire APRES VERIFICATION DES PERMUTATIONS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.42857142857142855\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "def score_mot_letter_diff(mot_tapé, mot_dico, score_max=3, pénalité_max=2):\n",
    "    assert isinstance(mot_tapé, str)\n",
    "    assert isinstance(mot_dico, str)\n",
    "    n1 = len(mot_tapé)\n",
    "    n2 = len(mot_dico)\n",
    "    n = min(n1, n2)\n",
    "    score = 0\n",
    "    for i in range (n):\n",
    "        score += score_letter_diff(mot_tapé[i], mot_dico[i])\n",
    "    return score*score_max/(pénalité_max*n)\n",
    "    \n",
    "print(score_mot_letter_diff(\"mime\", \"aimer\"))\n",
    "print(score_mot_letter_diff(\"mimeras\", \"aimeras\"))\n",
    "print(score_mot_letter_diff(\"mimeras\", \"jobastre\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inversions de lettre (WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette partie du code consiste à regarder si deux lettres successives du mot tapé sont les mêmes que les deux lettres successives au même endroit du mot dico, à permutation près. Dans ce cas, il faut retirer la pénalité dûe aux deux lettres dans le score précédent de lettres diff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisation : * score_max / (pénalité_max*min(len(w1), len(w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction principale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction agrège tous les scores calculés précédemment, puis les inverse pour obtenir une \"probabilité d'être le mot recherché\". On lui ajoute 1 pour être sur d'obtenir un score > 1, utile pour l'inversion qui nous permettra d'obtenir une proba plus petite que 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.4\n",
      "0.4347826086956522\n",
      "0.7692307692307692\n",
      "0.625\n",
      "0.36363636363636365\n",
      "0.4\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def score_total(mot_tapé, mot_dico):\n",
    "    return 1 + score_len(mot_tapé, mot_dico) + score_prem_lettre(mot_tapé, mot_dico) + score_mot_letter_diff(mot_tapé, mot_dico)\n",
    "\n",
    "def proba_mot_proche(mot_tapé, mot_dico):\n",
    "    return 1/score_total(mot_tapé, mot_dico)\n",
    "\n",
    "print(proba_mot_proche('habile','babil'))\n",
    "print(proba_mot_proche('babiller','babil'))\n",
    "print(proba_mot_proche('habit','babil'))\n",
    "print(proba_mot_proche('bâtit','babil'))\n",
    "print(proba_mot_proche('babike','babil'))\n",
    "print(proba_mot_proche('babio','babil'))\n",
    "print(proba_mot_proche('babiz','babil'))\n",
    "print(proba_mot_proche('baby','babil'))\n",
    "print(proba_mot_proche('bénin', 'babil'))\n",
    "print(proba_mot_proche('babil', 'babil'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autre méthode : édit distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(s1, s2):\n",
    "    # Nombre d'opérations nécessaires pour aller d'un mot à un autre (parmi suppression d'un carac, insertion, substitution)\n",
    "    dp = [[0 for j in range(len(s2)+1)] for i in range(len(s1)+1)]\n",
    "    for i in range(1, len(s2)+1):\n",
    "        dp[0][i] = i\n",
    "    \n",
    "    for i in range(1, len(s1)+1):\n",
    "        dp[i][0] = i\n",
    "\n",
    "    for i in range(1, len(s1) + 1):\n",
    "        for j in range(1, len(s2) + 1):\n",
    "            dp[i][j] = min(min(dp[i-1][j], dp[i][j-1]) + 1, dp[i-1][j-1] + (1 if s1[i-1] != s2[j-1] else 0))\n",
    "    \n",
    "    return dp[len(s1)][len(s2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits1(word):\n",
    "    \"\"\"All edits that are one edit away from 'word'\"\"\"\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    " \n",
    "    deletes = [L + R[1:] for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "    replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "    inserts = [L + c + R for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def editsk(word, k):\n",
    "    \"\"\"All edits that are k edits away from 'word'\"\"\"\n",
    "    e = edits1(word)\n",
    "    prev = e\n",
    "    for i in range(1, k):\n",
    "        temp = set(e2 for e1 in prev for e2 in edits1(e1))\n",
    "        e.update(temp)\n",
    "        prev = temp\n",
    "    e.discard(word)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
