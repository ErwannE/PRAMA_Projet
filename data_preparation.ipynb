{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'indexer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \u001b[38;5;66;03m# Pour les graphiques\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \u001b[38;5;66;03m# Pour la manipulation de tableaux de données\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspellchecker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpellChecker\n",
      "File \u001b[1;32mc:\\Users\\tidiane\\anaconda3\\Lib\\site-packages\\spellchecker\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m  \u001b[38;5;21;01mspellchecker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Spellchecker,getInstance\n",
      "File \u001b[1;32mc:\\Users\\tidiane\\anaconda3\\Lib\\site-packages\\spellchecker\\core.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minexactsearch\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mindexer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DictionaryIndex\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangdetect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _detect_lang\n\u001b[0;32m     29\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpellchecker\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgetInstance\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'indexer'"
     ]
    }
   ],
   "source": [
    "# Importations\n",
    "\n",
    "import numpy as np # Pour les calculs mathématiques\n",
    "import matplotlib.pyplot as plt # Pour les graphiques\n",
    "import pandas as pd # Pour la manipulation de tableaux de données\n",
    "from spellchecker import SpellChecker # Pour vérifier que le dataset d'entraînement ne contient pas de fautes d'orthographe ni de noms propres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nettoyage de la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouverture du fichier\n",
    "\n",
    "file_path = '/Users/quentingirard/Desktop/Ecole/2A_Ponts/S4/PRAMA/europarl-v6.fr-en.fr_toy'     #Chemin de la BDD jouet pour Quentin\n",
    "#file_path = '/Users/quentingirard/Desktop/Ecole/2A_Ponts/S4/PRAMA/europarl-v6.fr-en.fr_real'     #Chemin de la BDD complète pour Quentin\n",
    "\n",
    "file = open(file_path, 'r', encoding='utf-8')\n",
    "text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(text):\n",
    "    text = text.replace('à', 'a')\n",
    "    text = text.replace('â', 'a')\n",
    "    text = text.replace('é', 'e')\n",
    "    text = text.replace('è', 'e')\n",
    "    text = text.replace('ê', 'e')\n",
    "    text = text.replace('î', 'i')\n",
    "    text = text.replace('ô', 'o')\n",
    "    text = text.replace('ù', 'u')\n",
    "    text = text.replace('û', 'u')\n",
    "    text = text.replace('ç', 'c')\n",
    "    return text\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    text = text.replace('.', ' ')\n",
    "    text = text.replace('!', ' ')\n",
    "    text = text.replace('?', ' ')\n",
    "    text = text.replace(\"'\", ' ')\n",
    "    text = text.replace('\"', ' ')\n",
    "    text = text.replace(',', ' ')\n",
    "    text = text.replace(';', ' ')\n",
    "    text = text.replace('(', '')\n",
    "    text = text.replace(')','')\n",
    "\n",
    "    return text\n",
    "\n",
    "def remove_numbers(text):\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " est parvenu à interpréter et à respecter les différentes sensibilités présentes à la commission  y compris celles qui étaient de nature éthique \n",
      "pour ma part  en tant qu  homme de sciences  je suis extrêmement satisfait tant de la valeur intrinsèque particulière du rapport  qui place enfin l  europe dans les rangs des pays qui investissent le plus dans la recherche scientifique  que des nouvelles frontières qui s  ouvrent à la lutte contre des maladies terrifiantes  telles que certaines maladies dégénératives du système nerveux qui agissent sur le système nerveux central \n",
      "en outre  dans le domaine agroalimentaire  l  approbation d  un de mes amendements  qui prévoit que  pour les aliments transgéniques  avant leur introduction sur le marché  des tests de mutagénèse  d oncogénèse et de toxicité soient effectués obligatoirement  va dans la bonne direction pour gagner à nouveau la confiance des citoyens  particulièrement en ce qui concerne les institutions et le monde politique \n",
      "je remer\n"
     ]
    }
   ],
   "source": [
    "text = text.lower() # On met tout en minuscule - abandonné car on a besoin des majuscules pour identifier les noms propres.\n",
    "#text = remove_accents(text) # On enlève les accents\n",
    "text = remove_special_chars(text) # On remplace les caractères spéciaux par des espaces\n",
    "text = remove_numbers(text) # On enlève les chiffres\n",
    "print(text[1000:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['monicault', 'liikanen', 'vux', 'mutagénèse', 'europe', 'purvis', 'john', 'agroalimentaire', 'transgéniques', 'busquin', 'girard', 'oncogénèse', 'dégénératives']\n"
     ]
    }
   ],
   "source": [
    "## Vérification de la bonne orthographe des mots\n",
    "\n",
    "spell = SpellChecker(language='fr')\n",
    "\n",
    "words = text.split()\n",
    "misspelled = spell.unknown(words)\n",
    "\n",
    "list_misspelled = [word for word in misspelled if len(word) > 1]\n",
    "print(list_misspelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Vérification de la bonne identification des mots mal orthographiés et des noms propres\n",
    "misspelled_examples = ['ponnambalam','kumar','mutagénèse','busquin','tchernobyl']   #Attention, cette liste n'est pertinente que pour le dataset complet, et pas pour l'exemple jouet.\n",
    "for word in misspelled_examples:\n",
    "    print(word in list_misspelled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alors, on a deux choix : on peut enlever les mots mal orthographiés ou on peut les remplacer par une version corrigée. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of misspelled words: 3.49%\n"
     ]
    }
   ],
   "source": [
    "percentage_misspelled = round(len(list_misspelled) / len(words) * 100,2)\n",
    "print(f\"Percentage of misspelled words: {percentage_misspelled:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le plus simple est de drop ces mots. On s'affranchit à la fois des noms propres et des mots mal orthographiés. Un modèle plus fin pourra être réalisé par la suite car supprimer les mots mal orthographiés nuit au sens des phrases.\n",
    "\n",
    "On conserve les titres (ex :  M. Bonnefoi -> M est conservé)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouvelle longueur du texte: 373 mots\n",
      "Nouvelle longueur du texte: 359 mots\n"
     ]
    }
   ],
   "source": [
    "# On supprime les mots mal orthographiés et les noms propres\n",
    "\n",
    "print(f'Nouvelle longueur du texte: {len(text.split())} mots')\n",
    "for word in words:\n",
    "    if word in list_misspelled:\n",
    "        text = text.replace(word, '')\n",
    "\n",
    "#print(text[1000:2000])\n",
    "number_words = len(text.split())\n",
    "print(f'Nouvelle longueur du texte: {number_words} mots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je n'arrive pas à faire compiler la cellule ci-dessus pour le vrai dataset (ça tourne pendant des heures, je ne sais pas quoi utiliser pour améliorer la complexité de la fonction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du dataset d'entraînement à partir de la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Reprise': 1, 'de': 19, 'la': 8, 'session': 2, 'Je': 4, 'déclare': 1, 'reprise': 1, 'du': 3, 'Parlement': 1, 'européen': 1, 'qui': 11, 'avait': 1, 'été': 4, 'interrompue': 1, 'le': 10, 'vendredi': 1, '17': 1, 'décembre': 1, 'dernier': 1, 'et': 8, 'je': 3, 'vous': 6, 'renouvelle': 1, 'tous': 1, 'mes': 2, 'vux': 1, 'en': 3, 'espérant': 1, 'que': 4, 'avez': 3, 'passé': 1, 'bonnes': 1, 'vacances.': 1, 'Comme': 1, 'pu': 1, 'constater,': 1, 'grand': 1, '\"bogue': 1, \"l'an\": 1, '2000\"': 1, 'ne': 1, \"s'est\": 1, 'pas': 1, 'produit.': 1, 'En': 3, 'revanche,': 1, 'les': 8, 'citoyens': 1, \"d'un\": 1, 'certain': 2, 'nombre': 2, 'nos': 1, 'pays': 3, 'ont': 4, 'victimes': 1, 'catastrophes': 1, 'naturelles': 1, 'vraiment': 1, 'terribles.': 1, 'Vous': 1, 'souhaité': 1, 'un': 5, 'débat': 1, 'à': 7, 'ce': 3, 'sujet': 1, 'dans': 7, 'prochains': 1, 'jours,': 1, 'au': 1, 'cours': 1, 'cette': 2, 'période': 1, 'session.': 1, 'attendant,': 1, 'souhaiterais,': 1, 'comme': 1, 'collègues': 1, 'me': 1, \"l'ont\": 1, 'demandé,': 1, 'nous': 1, 'observions': 1, 'une': 2, 'minute': 3, 'silence': 1, 'pour': 4, 'toutes': 1, 'victimes,': 1, 'des': 6, 'tempêtes': 1, 'notamment,': 1, 'différents': 1, \"l'Union\": 1, 'européenne': 1, 'touchés.': 1, 'invite': 1, 'lever': 1, 'silence.': 1, 'suis': 2, 'Monsieur': 2, 'Girard,': 1, 'êtes': 1, 'M.': 3, 'De': 1, 'Monicault.': 1, '(Le': 1, 'Parlement,': 1, 'debout,': 1, 'observe': 1, 'silence)': 1, 'Il': 1, \"s'\": 2, 'est': 2, 'agi': 1, \"d'\": 6, 'travail': 1, 'intelligent': 1, 'intégré': 1, 'parvenu': 1, 'interpréter': 1, 'respecter': 1, 'différentes': 1, 'sensibilités': 1, 'présentes': 1, 'Commission,': 1, 'y': 1, 'compris': 1, 'celles': 1, 'étaient': 1, 'nature': 1, 'éthique.': 1, 'Pour': 1, 'ma': 1, 'part,': 1, 'tant': 2, \"qu'\": 1, 'homme': 1, 'sciences,': 1, 'extrêmement': 1, 'satisfait': 1, 'valeur': 1, 'intrinsèque': 1, 'particulière': 1, 'rapport,': 1, 'place': 1, 'enfin': 1, \"l'\": 4, 'Europe': 1, 'rangs': 1, 'investissent': 1, 'plus': 1, 'recherche': 1, 'scientifique,': 1, 'nouvelles': 1, 'frontières': 1, 'ouvrent': 1, 'lutte': 1, 'contre': 1, 'maladies': 2, 'terrifiantes,': 1, 'telles': 1, 'certaines': 1, 'dégénératives': 1, 'système': 2, 'nerveux': 2, 'agissent': 1, 'sur': 2, 'central.': 1, 'outre,': 1, 'domaine': 1, 'agroalimentaire,': 1, 'approbation': 2, 'amendements,': 1, 'prévoit': 1, 'que,': 1, 'aliments': 1, 'transgéniques,': 1, 'avant': 1, 'leur': 1, 'introduction': 1, 'marché,': 1, 'tests': 1, 'mutagénèse,': 1, \"d'oncogénèse\": 1, 'toxicité': 1, 'soient': 1, 'effectués': 1, 'obligatoirement,': 1, 'va': 1, 'bonne': 1, 'direction': 1, 'gagner': 1, 'nouveau': 1, 'confiance': 1, 'citoyens,': 1, 'particulièrement': 1, 'concerne': 1, 'institutions': 1, 'monde': 1, 'politique.': 1, 'remercie': 1, 'encore': 1, 'John': 1, 'Purvis': 2, 'avoir': 1, 'permis': 1, 'ensemble': 1, 'amendements.': 1, 'MM.': 1, 'Busquin': 1, 'Liikanen,': 1, 'but': 1, 'être': 1, 'compétitifs': 1, 'relever': 1, 'défi': 1, 'mondial.': 1, 'Président,': 1, 'a': 1, 'bien': 1, 'traité': 1, 'son': 1, 'dossier.': 1, 'Beaucoup': 1, 'déjà': 1, 'dit.': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurence</th>\n",
       "      <th>fréquence (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mot</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Reprise</th>\n",
       "      <td>1</td>\n",
       "      <td>0.278552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>19</td>\n",
       "      <td>5.292479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <td>8</td>\n",
       "      <td>2.228412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session</th>\n",
       "      <td>2</td>\n",
       "      <td>0.557103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Je</th>\n",
       "      <td>4</td>\n",
       "      <td>1.114206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         occurence  fréquence (%)\n",
       "mot                              \n",
       "Reprise          1       0.278552\n",
       "de              19       5.292479\n",
       "la               8       2.228412\n",
       "session          2       0.557103\n",
       "Je               4       1.114206"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialisation d'un dictionnaire\n",
    "word_counts = {}\n",
    "\n",
    "# Comptage des occurences des mots et remplissage du dictionnaire\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        if word in word_counts:\n",
    "            word_counts[word] += 1\n",
    "        else:\n",
    "            word_counts[word] = 1\n",
    "\n",
    "# Conversion du dictionnaire en DataFrame\n",
    "df = pd.DataFrame(list(word_counts.items()), columns=['mot', 'occurence'])\n",
    "df.set_index('mot', inplace=True)\n",
    "df['fréquence (%)'] = df['occurence'] / number_words * 100\n",
    "\n",
    "print(word_counts)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
